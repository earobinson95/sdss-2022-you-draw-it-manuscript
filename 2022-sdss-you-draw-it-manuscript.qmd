---
title: "'You Draw It': Implementation of visually fitted trends with `r2d3`"
bibliography: references.bib
abstract: "How do statistical regression results compare to intuitive, visually fitted results? Fitting lines by eye through a set of points has been explored since the 20th century. Common methods of fitting trends by eye involve maneuvering a string, black thread, or ruler until the fit is suitable, then drawing the line through the set of points. In 2015, the New York Times introduced an interactive feature, called 'You Draw It,' where readers are asked to input their own assumptions about various metrics and compare how these assumptions relate to reality. This research is intended to implement 'You Draw It', adapted from the New York Times, as a way to measure the patterns we see in data."
author: 
  - Emily A. Robinson
  - Reka Howard
  - Susan VanderPlas
keywords: 'graphics, user interaction, regression'
format: 
  pdf:
    include-in-header:
      - edits.tex
      # - refs.tex
    keep-tex: true
    # template: template.tex
documentclass: jds
---

<!-- Article Types -->
<!-- https://jds-online.org/journal/JDS/information/Article%20Types -->

<!-- Statistical Data Science -->

<!-- This section is the home base of the reformed journal covering statistical methods that are motivated by real-world applications. It is not for papers with technical proofs that push the frontiers of theoretical developments. In addition to classic topics in Statistics, cutting-edge works on big data, visualization, machine learning, and artificial intelligence are also welcome. -->

<!-- Computing in Data Science -->

<!-- Computing is an indispensable component of all data science and big data applications. As more journals on data science and big data emerge, it is of great interest for the data science community to have a highly regarded outlet with a specialization in computing, covering a wide spectrum from methods, algorithms, software implementations, to case studies. Existing journals on statistical computing have their own traditions and may not meet the increasing demands. Some research works on cutting-edge problems may not fit well in any existing journal. -->

<!-- This section covers the following types of articles. -->
<!-- 1. Software: Articles here are similar to those in the Journal of Statistical Software. They are not referencing manuals but vignettes that introduce the methods being implemented as well as the usage of the software with reproducible code chunks. The software implementation can be in any computer language with a sufficiently large user base. -->
<!-- 2. Algorithms: Articles here focus on the performance side of the computing needs arising from domain applications. For example, one can propose algorithms that make infeasible tasks feasible or speed up existing algorithms. -->
<!-- 3. Methods: Articles here are similar to those in Journal of Computational and Graphic Statistics or Statistics and Computing. The computing methods need to be motivated by a domain application with the properties carefully studied. -->

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = F, 
                      eval = T, 
                      fig.path="./images/", 
                      fig.env="figure*", 
                      fig.align = "center")
library(readr)
library(tidyverse)
library(knitr)
library(bibtex)
theme_set(theme_bw())

library(readxl)
library(lubridate)
library(patchwork)
```

```{r eyefitting-data, message=FALSE, warning=FALSE, echo = F}
eyefitting_model_data <- read_csv("data/eyefitting-model-data.csv") %>%
  dplyr::rename(`Parameter Choice` = parm_id)

eyefitting_simulated_data <- read_csv("data/eyefitting-simulated-data.csv") %>%
  dplyr::rename(`Parameter Choice` = parm_id)

eyefitting_parameters <- read_csv("data/eyefitting-parameters.csv") %>%
  dplyr::rename(`Parameter Choice` = parm_id)

eyefitting_lmer_preds <- read_csv("data/eyefitting-lmer-preds.csv") %>%
  dplyr::rename(`Parameter Choice` = parm_id)

eyefitting_gamm_preds <- read_csv("data/eyefitting-gamm-preds.csv") %>%
  dplyr::rename(`Parameter Choice` = parm_id)

eyefitting_example_sim <- read.csv("data/eyefitting-simdata-example.csv")

youdrawit_model_data      <- read_csv("data/youdrawit-model-data.csv")  %>%
  mutate(`Points Truncated` = ifelse(points_truncated == 10, "50%", "75%"),
         `Growth Rate` = ifelse(beta == "beta0.1", "Low", "High")) %>%
  mutate(`Growth Rate` = factor(`Growth Rate`, levels = c("Low", "High"))) %>%
  filter(`Points Truncated` == "50%", `Growth Rate` == "High")

youdrawit_simulated_band <- youdrawit_model_data %>%
  group_by(`Growth Rate`, `Points Truncated`, x) %>%
  summarize(min_ynls = min(ynls),
            max_ynls = max(ynls))
```

```{r eyefitting-simplot, eval = F, warning = F, message = F}
#| fig-cap: "Example of simulated data points displayed in a scatterplot illustrating the trends associated with the four selected parameter choices."
#| out-width: \columnwidth
#| label: fig-eyefitting-simplot
#| fig-res: 300
#| fig-width: 9
#| fig-height: 9
#| fig-env: figure
          
eyefitting_example_simplot <- eyefitting_example_sim %>%
  filter(data == "point_data") %>%
  filter(dataset %in% c("F", "N", "S") | (x < 16 & x > 4)) %>%
  mutate(dataset = factor(dataset, levels = c("S", "F", "V", "N"))) %>%
  filter(`Parameter Choice` == "F") %>%
  dplyr::rename(`Parameter Choice` = dataset) %>%
  ggplot(aes(x = x, y = y)) +
  geom_point(size = 1) +
  facet_wrap(~`Parameter Choice`, ncol = 2) +
  theme_bw(base_size = 14) +
  theme(aspect.ratio = 1,
  legend.position = "none",
  plot.title   = element_text(size = 12, hjust = 0),
  axis.text    = element_text(size = 12),
  axis.title   = element_text(size = 12),
  legend.title = element_text(size = 12),
  legend.text  = element_text(size = 12),
  # strip.text = element_text(size = 5, margin = margin(0.05,0,0.05,0, "cm")),
  # strip.background = element_rect(size = 0.5),
  legend.key.size = unit(1, "line")
) +
  scale_y_continuous(breaks = seq(-10, 20, 5))
# eyefitting_example_simplot
```

```{r eyefitting-trial-plot, warning = F, message = F}
#| fig-cap: "Example of validation feedback data where three trend lines show the the OLS fitted, PCA fitted, and participant drawn values overlaid on the simulated data points."
#| out-width: \columnwidth
#| label: fig-eyefitting-trial-plot
#| fig-res: 300
#| fig-width: 4
#| fig-height: 4
#| fig-env: figure
#| 

eyefitting_example <- eyefitting_model_data %>%
  # filter(participant_id == "65c10d498eae365e108efcd3dcb75287", parm_id == "N") %>%
  filter(participant_id == "60b16b9bd5a122c1457d31055df51a45", `Parameter Choice` == "F") %>%
  ggplot(aes(x = x)) +
  geom_line(aes(y = yols, color = "OLS", linetype = "OLS")) +
  geom_line(aes(y = ypca, color = "PCA", linetype = "PCA")) +
  geom_line(aes(y = ydrawn, color = "Drawn", linetype = "Drawn")) +
  geom_point(data = eyefitting_simulated_data %>%
               filter(dataset == "point_data", participant_id == "60b16b9bd5a122c1457d31055df51a45", `Parameter Choice` == "F"),
             aes(x = x, y = y)) +
  facet_wrap(~`Parameter Choice`, labeller = labeller(`Parameter Choice` = label_both)) +
  theme_bw(base_size = 14) +
  theme(aspect.ratio = 1,
        legend.position = "bottom",
        plot.title   = element_text(size = 14, hjust = 0),
        axis.text    = element_text(size = 12),
        axis.title   = element_text(size = 12),
        legend.title = element_text(size = 12),
        legend.text  = element_text(size = 12),
        # strip.text = element_text(size = 8, margin = margin(0.1,0,0.1,0, "cm")),
        # strip.background = element_rect(size = 0.8),
        legend.key.size = unit(1, "line")
        ) +
  scale_x_continuous(limits = c(0,20)) +
  scale_color_manual("", values = c("black", "steelblue", "orange")) +
  scale_linetype_manual("", values = c("dashed", "solid", "solid")) +
  scale_y_continuous("y")

# eyefitting_example
```

```{r eyefitting-lmer-residualplots, warning = F, message = F}
#| fig-cap: "Estimated trends of residuals (vertical deviation of participant drawn points from both the OLS (blue) and PCA (orange) fitted points) as fit by the linear mixed model. A random sample of 75 participants was selected to display the individual participant residuals behind the overall trend."
#| out-width: \columnwidth
#| label: fig-eyefitting-lmer-residualplots
#| fig-res: 300
#| fig-width: 9
#| fig-height: 9
#| fig-env: figure
#| 

set.seed(68505)
participant_sample <- sample(unique(eyefitting_model_data$prolific_id), 75)

# Plot Predictions
eyefitting_lmer_plot <- eyefitting_lmer_preds %>%
  filter((`Parameter Choice` %in% c("F", "N", "S") | (x <= 16 & x >= 4))) %>%
  mutate(`Parameter Choice` = factor(`Parameter Choice`, levels = c("S", "F", "V", "N"))) %>%
  filter(`Parameter Choice` == "F") %>%
  ggplot(aes(x = x)) +
  geom_line(data = eyefitting_model_data %>% 
              filter(prolific_id %in% participant_sample)  %>% filter(`Parameter Choice` == "F"), 
            aes(x = x, y = residual_ols_loess, group = plot_id, color = "OLS"), alpha = 0.1) +
  geom_line(data = eyefitting_model_data %>% 
              filter(prolific_id %in% participant_sample) %>% filter(`Parameter Choice` == "F"), 
            aes(x = x, y = residual_pca_loess, group = plot_id, color = "PCA"), alpha = 0.1) +
  geom_ribbon(aes(ymin = asymp.LCL.ols, ymax = asymp.UCL.ols, fill = "OLS"), color = NA, alpha = 0.4) +
  geom_line(aes(y = emmean.ols, color = "OLS")) +
  geom_ribbon(aes(ymin = asymp.LCL.pca, ymax = asymp.UCL.pca, fill = "PCA"), color = NA, alpha = 0.4) +
  geom_line(aes(y = emmean.pca, color = "PCA")) +
  geom_hline(yintercept = 0, linetype = "dashed", alpha = 0.5) +
  facet_wrap(~`Parameter Choice`, labeller = labeller(`Parameter Choice` = label_both), scales = "free") +
  theme_bw(base_size = 14) +
  theme(aspect.ratio = 1,
        legend.position = "bottom",
        plot.title   = element_text(size = 14, hjust = 0),
        axis.text    = element_text(size = 12),
        axis.title   = element_text(size = 12),
        legend.title = element_text(size = 12),
        legend.text  = element_text(size = 12),
        # strip.text = element_text(size = 5, margin = margin(0.05,0,0.05,0, "cm")),
        # strip.background = element_rect(size = 0.5),
        legend.key.size = unit(1, "line"), legend.box="vertical", legend.margin=margin()
        ) +
  scale_y_continuous("Residual", limits = c(-5,5), breaks = seq(-5,5,2.5)) +
  scale_color_manual("Individual participant \nresiduals", values = c("steelblue", "orange"), labels = c("OLS", "PCA")) +
  scale_fill_manual("LMER fitted trend", values = c("steelblue", "orange"), labels = c("OLS", "PCA"))  +
  guides(color = guide_legend(override.aes = list(alpha = 1)),
         fill = guide_legend(override.aes = list(alpha = 1)))

# eyefitting_lmer_plot
```

```{r eyefitting-gamm-residualplots, warning = F, message = F}
#| fig-cap: "Estimated trends of residuals (vertical deviation of participant drawn points from both the OLS (blue) and PCA (orange) fitted points) as fit by the generalized additive mixed model. A random sample of 75 participants was selected to display the individual participant residuals behind the overall trend."
#| out-width: \columnwidth
#| label: fig-eyefitting-gamm-residualplots
#| fig-res: 300
#| fig-width: 9
#| fig-height: 9
#| fig-env: figure
#| 

eyefitting_gamm_plot <- eyefitting_gamm_preds %>%
  filter((`Parameter Choice` %in% c("F", "N", "S") | (x <= 16 & x >= 4))) %>%
  mutate(`Parameter Choice` = factor(`Parameter Choice`, levels = c("S", "F", "V", "N"))) %>%
  filter(`Parameter Choice` == "F") %>%
  ggplot(aes(x = x)) +
  geom_line(data = eyefitting_model_data %>% 
              filter(prolific_id %in% participant_sample)  %>% filter(`Parameter Choice` == "F"), 
            aes(x = x, y = residual_ols_loess, group = plot_id, color = "OLS"), alpha = 0.1) +
  geom_line(data = eyefitting_model_data %>% 
              filter(prolific_id %in% participant_sample)  %>% filter(`Parameter Choice` == "F"), 
            aes(x = x, y = residual_pca_loess, group = plot_id, color = "PCA"), alpha = 0.1) +
  geom_ribbon(aes(ymin = ols.lower, ymax = ols.upper, fill = "OLS"), color = NA, alpha = 0.4) +
  geom_line(aes(y = ols.pred, color = "OLS")) +
  geom_ribbon(aes(ymin = pca.lower, ymax = pca.upper, fill = "PCA"), color = NA, alpha = 0.4) +
  geom_line(aes(y = pca.pred, color = "PCA")) +
  geom_hline(yintercept = 0, linetype = "dashed", alpha = 0.5) +
  facet_wrap(~`Parameter Choice`, labeller = labeller(`Parameter Choice` = label_both), scales = "free") +
  theme_bw(base_size = 14) +
  theme(aspect.ratio = 1,
        legend.position = "bottom",
        plot.title   = element_text(size = 14, hjust = 0),
        axis.text    = element_text(size = 12),
        axis.title   = element_text(size = 12),
        legend.title = element_text(size = 12),
        legend.text  = element_text(size = 12),
        # strip.text = element_text(size = 5, margin = margin(0.05,0,0.05,0, "cm")),
        # strip.background = element_rect(size = 0.5),
        legend.key.size = unit(1, "line"), legend.box="vertical", legend.margin=margin()
        ) +
  scale_y_continuous("Residual", limits = c(-5,5), breaks = seq(-5,5,2.5)) +
  scale_color_manual("Individual participant \nresiduals", values = c("steelblue", "orange"), labels = c("OLS", "PCA")) +
  scale_fill_manual("GAMM fitted trend", values = c("steelblue", "orange"), labels = c("OLS", "PCA"))   +
  guides(color = guide_legend(override.aes = list(alpha = 1)),
         fill = guide_legend(override.aes = list(alpha = 1)))

# eyefitting_gamm_plot
```

# Introduction

We all use statistical graphics, but how do we know that the graphics we use are communicating effectively?
Through experimentation, graphical testing methods allow researchers to conduct studies designed to understand how we perceive graphics and perform graphical tasks such as differentiation, prediction, estimation, and extrapolation. 
Each of these levels of interaction with a graph require a different method of engagement with and use of the information presented in a chart.
In this paper, we describe the adaptation of an old tool for graphical testing and evaluation, eye-fitting, for use in modern web-applications suitable for testing statistical graphics. 
We present an empirical evaluation of this testing method for linear regression, and briefly discuss an extension of this method to non-linear applications.

One of the most common charts created is a scatterplot of points over time; these charts show up regularly in news articles and in scientific publications alike.
These charts rely on our ability to identify and detect trends in data. 
Our visual system is naturally built to look for structure and identify patterns, including patterns and trends over time; many times we do not even notice this process happening subconsciously.
As shown in @fig-gas-prices, a viewer engaging with a plot of weekly average gas prices over time may perform several cognitive operations. First, they scan the plot and assesses points to determine if there are any outliers or otherwise remarkable points. Then, they may fit a rough mental smooth/trend line to the points to summarize the useful information and remove variability. Finally, an interested and engaged viewer may pull in additional contextual information from long-term memory, seeking to explain variation in the mental 'trend' with supplemental information, such as COVID lock downs which reduced gasoline demand and the beginning of the war in Ukraine, which wreaked havoc on the supply and demand for global energy sources.

```{r gas-prices, echo = F, message = F, warning = F}
#| fig-cap: "Weekly average gas prices in the United States, 2019-June 2022. Additional mental operations a viewer might perform while looking at the plot are annotated in grey [@usenergyinformationadministrationWeeklyAllGrades2022]."
#| out-width: \columnwidth
#| label: fig-gas-prices
#| fig-res: 300
#| fig-width: 8
#| fig-height: 4
#| fig-env: figure

gas <- read_xls("EMM_EPM0_PTE_NUS_DPGw.xls", skip = 3, sheet = 2) %>%
  set_names(c("Date", "Price"))

annotations <- tibble(
  xmin = as.POSIXct(ymd(c("2020-03-15", "2022-02-26"))),
  xmax = as.POSIXct(ymd(c("2020-05-30", "2022-06-29"))),
  ymin = -Inf,
  ymax = Inf,
  label = c("COVID lockdowns", "War in Ukraine")
)
ggplot(gas, aes(x = Date, y = Price)) + 
  geom_rect(data = annotations, aes(xmin = xmin, xmax = xmax, ymin = ymin, ymax = ymax), alpha= 0.2, fill = "grey", inherit.aes = F) + 
  geom_text(data = annotations, aes(x = xmin, y = 1, label = label), color = "grey") + 
  ylab("Price per Gallon ($)") + 
  ggtitle("Weekly Average Gas Prices in the United States, 2019 - 2022", subtitle = "US Energy Information Administration") + 
  geom_point() + 
  scale_x_datetime(limits = as.POSIXct(ymd("2019-01-01", "2022-06-29"))) + 
  geom_line(se = F, color = "grey", method = "loess", span = .1, alpha = .5, stat = "smooth", size = 1.5)
```

Initial studies in the 20th century explored the use of fitting lines by eye through a set of points [@finney1951subjective; @mosteller1981eye; @unwin1988eyeballing]. Common methods of fitting trends by eye involved maneuvering a string, black thread, or ruler until the fit was suitable, then drawing the line through the set of points. Results from these early studies provided groundwork for visually judging slopes and selecting accurate starting values for common iterative calculations. Recently, @ciccione2021can conducted a comprehensive set of studies investigating human ability to detect trends in graphical representations from a psychophysical approach.
<!-- \svp{XXX and found what? Describe the results XXX} -->
This set of studies asked participants to judge trends, estimate slopes, and conduct extrapolation by using a track-pad to adjust the tilt of a line on the screen. 
Results indicated the slopes participants reported were always in excess of the ideal slopes, both in the positive and in the negative direction, and those biases increased with noise and with number of points. 
This supported the results found in @mosteller1981eye and suggested that participants might use Deming regression [@deming1943statistical], which minimizes the Euclidean distance of points from the line, when fitting a line to a noisy scatterplot.

While psychologists and statisticians have been using eye-fitting techniques to assess our innate perceptual statistical modeling abilities, news organizations have used similar techniques in order to draw readers in and demonstrate the difference between readers' assumptions and reality.
In 2015, the New York Times (NYT) introduced an interactive feature, called 'You Draw It' [@aisch2015you], where readers input their own assumptions about various metrics of news interest and compare these assumptions to reality. 
The NYT team used Data Driven Documents (D3), a JavaScript library that allows readers to interact with a chart directly by drawing a line on their computer screen with a mouse. Despite the somewhat different purpose behind this feature, the D3 driven method used by the NYT is wonderfully intuitive, and does not require the assumption of linearity, making it much more adaptable to testing how viewers perceive and predict when presented with non-linear data.

We set out to implement ‘You Draw It’, adapted from the NYT feature, as a way to experimentally assess the patterns we see in data. 
Here, we provide technical details of the software development, utilizing interactive graphics in R [@r-software]. 
We then share results from our study which validates 'You Draw It' as a method for graphical testing on linear trends and apply an appropriate data analysis method to the participant data. We also briefly demonstrate the use of the 'You Draw It' method and analysis on nonlinear data.

# Development 

## 'You Draw It' v0

<!-- \svp{Describe the NYT code - what it does, how it works (for loop to connect mouse coordinates to closest point via inverting the scales)} -->

The NYT uses D3, Data Driven Documents [@bostock2011d3], to create many of the interactive data graphics that users rely on, from the famous "election needle" in 2016 to their COVID dashboards. 
Naturally, this same framework was used to create the 'You Draw It' feature.
The NYT code used to create the initial D3 plot and 'You Draw It' interactive feature includes multiple working parts. First, the relationship between coordinate mappings and pixels sets up the chart and the initial data is plotted. Next, the `d3.drag` function adds user interactivity and observes the movement of the user's mouse. Additionally, the `forEach` loop finds the closest point in the coordinate system to the user's mouse. Finally, the code detects if all points are filled by the user and updates the status of the task.

When working with a new programming language, setting up a new development environment can be challenging. As R users, we found the software overhead required to develop straight JavaScript code to be intimidating [@wattenberger-fullstack], but luckily, the R community anticipated this barrier. In the next section, we will see how the `r2d3` package [@r2d3pkg] in R can be used to render the JavaScript code and display D3 visuals in familiar R HTML formats such as Rmarkdown and Shiny.

## Generating D3 Plots in R

<!-- \svp{Describe the process of using `r2d3`} -->
We leveraged the `r2d3` package to take data randomly generated in R and create a D3 plot that could be modified with the 'You Draw It' script. This step allowed us to more easily connect the data generation process with the resulting D3 code without having to generate new code manually each time we re-generated the data. While not strictly necessary for the validation test of the 'You Draw It' method compared to past linear regression methods presented in this paper, this abstraction makes it much easier to test arbitrary or model-generated data which is unique to each participant.

We conducted all data simulation and processing in R and output two data sets - *point data* and *line data* - containing $(x, y)$ coordinates corresponding to either a simulated point or fitted value predicted by a statistical model respectively. Then, the `r2d3` package converts the data sets in R to JavaScript Object Notation (JSON) to be interpreted by JavaScript code included with the `r2d3` package. 
Parameters for aesthetic design choices are defined in a list of options in the `r2d3` function call; `r2d3` passes these to the generated JavaScript code.
For instance, we can specify the buffer space allowed for the $x$ and $y$ axes to avoid users anchoring their lines to the axes limits. 

## Adding 'You Draw It' Functionality

In order to make use of the original 'You Draw It' code for perceptual experiments, we first needed to accommodate an additional layer. The original NYT features asked participants to draw on a blank coordinate grid, as shown in @fig-nyt-screenshot.

![Screenshot of the [You Draw It application](https://www.nytimes.com/interactive/2015/05/28/upshot/you-draw-it-how-family-income-affects-childrens-college-chances.html) originally developed by the New York Times.](images/NYT-You-Draw-It-Screenshot.png){#fig-nyt-screenshot
width='\columnwidth'}

When testing perception of graphics, however, we want to pre-populate the chart with additional information - points, and in some cases, portions of a trend line. This requires that we modify the original JavaScript source code to accommodate these additional elements, which we generate using `r2d3`, as described above.

As previously discussed, we modified `r2d3` code to draw the initial plot and data. Drag events in `D3.js` are utilized to observe and react to user input, as in the original 'You Draw It' script from the NYT. ^[The full source code we developed for the 'You Draw It' task is available at \url{https://github.com/earobinson95/presentations/blob/master/can-you-draw-it/www/you-draw-it.js}.] We adapted initial code from @pearce_2019 and @furic_2017.
<!-- \ear{Rename js code to you-draw-it}. -->

<!-- Note, we didn't modify d3.js directly, we just added additional functions that would interpret our JSON file and draw the appropriate plot. These functions were modified from the defaults automatically generated by `r2d3` -->

<!-- \ear{Reference https://bl.ocks.org/1wheel/07d9040c3422dac16bd5be741433ff1e and https://github.com/BenoitFuric/you-draw-it-graph.} -->

One constraint we inherited from the NYT code is that users can only draw one-to-one functions; because the code works with drag events, each point in $x$ can correspond to only one point in $y$, at least as the code is currently written. 
While this is not particularly problematic for our applications to date, it might limit applications of this type of user interaction when assessing user drawn confidence bands, ribbons, and other situations where two or more vertical points are required.
<!-- \svp{XXX additional details of how we accomplished this XXX} -->

## Visual Cues

During testing of our modifications to the 'You Draw It' script, we discovered that frequently the JavaScript code would ``skip" from point to point out of sequence. This resulted in a jagged line (visually) with missing values in the underlying stored array of data; as a result, the for-loop controlling the user-drawn line never exited and the user's data was not recorded. While it would have been possible to fix this using some sort of interpolation algorithm, we did not want to compromise user results by introducing interpolation artifacts, so we opted instead for a visual cue that fixed the problem by modifying the human behavior.

![You Draw It task plot as shown to user.    
**left:** Initial state, with instructions *Use your mouse to fill in the trend in the yellow box region.*    
**middle:** User view during task completion.    
**right:** Finished state](images/ydi-stimuli.png){#fig-you-draw-it-task-plot}

As shown in @fig-you-draw-it-task-plot, the user-filled portion of the plot is represented with a yellow rectangle, which adapts to the user's input and spans any missing values. 
When the box disappears, the array is filled in and the user can submit their response.

One challenge introduced by adding this visual cue is that D3 uses Scalable Vector Graphics (SVG) to render elements. 
Adding an additional layer meant that we had to ensure that not only the grids, lines, and points of the default scatterplot and trend line rendered in the correct order, but that the yellow box rendered behind all of these points as well so that no information was masked; and that this layer order updated in real time.

## Connecting to Shiny
Shiny Messages are used to communicate the user interaction between the JavaScript code and the R environment. 
The initial plot is rendered using Shiny's `RenderD3` and `d3Output` functions; subsequent user interactions are controlled via the JavaScript code. Once the user is finished modifying the plot, they can submit their response, so long as they have filled in all of the points. This is enforced using Shiny's message-passing interface and a JavaScript hook that notifies Shiny when the array of user-drawn points is completely filled in.
Once the user is done drawing the line, we save the results of the drawn line to a SQLite database, using Shiny to pass data from JavaScript to R. 
The connections between each portion of the app are shown in @fig-you-draw-it-code-sketch.


![Sketch of underlying code for 'You Draw It', illustrating the data simulation conducted in R, the initial setup of the visual stimuli with D3 source code, along with the iterative process between the user interaction and plotting in Shiny. Once the user is done drawing the line, we saved the results of the drawn line to a database for analysis.](images/code-sketch-2.png){#fig-you-draw-it-code-sketch}

One additional challenge when integrating the D3 graphics into the Shiny application is that by default, most Shiny applications use a reactive framework that adjusts to the user's browser size. When working with D3, however, this can be problematic: most D3 parameters are specified at the pixel level. The discontinuity between the assumptions of Shiny and D3 meant that we had to fix the size of the Shiny element, and then perform a check to ensure that the user's screen was sufficiently big to render the plot. While in an ideal world, users could participate using cell phones, tablets, and traditional laptop/desktop computers, functionally our checks limited users' ability to participate using smaller screen sizes found in cell phones and some tablets.
Additionally, after some feedback by laptop users during pilot testing, we included an additional requirement that participants have a computer mouse available; the results from touchpad users were qualitatively different (more jagged) in ways suggesting that the recorded data did not adequately describe users' perceptions.

# Application

<!-- \svp{Describe the experiment formally. Don't be afraid to quote Mosteller's paper if you think it's necessary. Focus on one set of plots from the Mosteller paper and one set of plots from our exponential stuff, so you're demonstrating linear and nonlinear analysis. Include basic demographics, and compare to Mosteller's paper - we also had a sample of highly educated individuals. Right now you have a very short summary, but you need to actually explain the full process behind it, with all of the details you'd expect from a full experimental writeup.} -->

## Validation Study

We conducted a study in order to validate 'You Draw It' as a method for graphical testing, comparing results to the less technological method utilized in @mosteller1981eye.
The original study asked 153 graduate students and postdoctoral researchers in an Introductory Biostatistics course to fit lines by eye to a set of four points (S, F, V, N), each set with differing slope and variance properties, using an 8.5 x 11 inch transparency with a straight line etched across the middle.
Researchers conducted the study with a latin square experimental design to test for a practice effect on the task.
Qualitative analysis suggested that participants tended to fit the slope of the first principal component (minimizes Euclidean distance) as opposed to the slope from the ordinary least squares regression (minimizes vertical distance) [@fig-pca-plot] and found no effect of order.

```{r ols-vs-pca-example, message = F, warning = F}
#| fig-cap: "Comparison between an OLS regression equation which minimizes the vertical distance of points from the line and a regression equation with a slope calculated by the first principal component which minimizes the smallest distance of points from the line."
#| out-width: "70%"
#| label: fig-pca-plot
#| fig-res: 300
#| fig-width: 6
#| fig-height: 4
#| fig-env: figure

library(ggplot2)
library(magrittr)
library(plyr)

set.seed(2)
corrCoef = 0.5 # sample from a multivariate normal, 10 datapoints
dat = MASS::mvrnorm(10,c(0,0),Sigma = matrix(c(1,corrCoef,2,corrCoef),2,2))
dat[,1] = dat[,1] - mean(dat[,1]) # it makes life easier for the princomp
dat[,2] = dat[,2] - mean(dat[,2])

dat = data.frame(x1 = dat[,1],x2 = dat[,2])

# Calculate the first principle component
# see http://stats.stackexchange.com/questions/13152/how-to-perform-orthogonal-regression-total-least-squares-via-pca
v = dat%>%prcomp%$%rotation
x1x2cor = bCor = v[2,1]/v[1,1]

x1tox2 = coef(lm(x1~x2,dat))
x2tox1 = coef(lm(x2~x1,dat))
slopeData = data.frame(slope = c(x1x2cor,x2tox1[2]),
                       type=c("Principal Component", "Ordinary Least Squares"))

# We want this to draw the neat orthogonal lines.
pointOnLine = function(inp){
  # y = a*x + c (c=0)
  # yOrth = -(1/a)*x + d
  # yOrth = b*x + d
  x0 = inp[1] 
  y0 = inp[2] 
  a = x1x2cor
  b = -(1/a)
  c = 0
  d = y0 - b*x0
  x = (d-c)/(a-b)
  y = -(1/a)*x+d
  return(c(x,y))
}

points = apply(dat,1,FUN=pointOnLine)

segmeData = rbind(data.frame(x=dat[,1],y=dat[,2],xend=points[1,],yend=points[2,],type = "Principal Component"),
                  data.frame(x=dat[,1],y=dat[,2],yend=dat[,1]*x2tox1[2],xend=dat[,1],type="Ordinary Least Squares"))

ols_pca_plot <- dat %>%
ggplot(aes(x1,x2))+
  geom_point()+
  geom_abline(data=slopeData,aes(slope = slope,intercept=0,color=type, linetype=type), size = 1.2)+
  geom_segment(data=segmeData,aes(x=x,y=y,xend=xend,yend=yend,color=type, linetype=type))+
  facet_grid(.~type)+
  coord_equal()+
  scale_x_continuous("x") +
  scale_y_continuous("y") +
  theme_bw(base_size = 14) +
  theme(aspect.ratio = 1,
        legend.position = "none",
        axis.text    = element_text(size = 12),
        axis.title   = element_text(size = 12),
        legend.title = element_blank(),
        # legend.text  = element_text(size = 10),
        # strip.text = element_text(size = 8, margin = margin(0.1,0,0.1,0, "cm")),
        # strip.background = element_rect(size = 0.8),
        legend.key.size = unit(1, "line")
        ) +
  scale_color_manual(values = c("steelblue", "orange"), labels = c("OLS", "PCA")) +
  scale_linetype_manual(values = c("solid", "dashed"), labels = c("OLS", "PCA"))
ols_pca_plot
```

In our study, we replicated @mosteller1981eye using the 'You Draw It' method and simulated data with parameter coefficients selected to reflect those from the four data sets in the original study. Data were simulated based on a linear model with additive errors:
\begin{align}
y_i & = \beta_0 + \beta_1 x_i + e_i \\
\text{with } e_i & \sim N(0, \sigma^2). \nonumber
\end{align} 
For each participant, four unique data sets were randomly and independently generated from the underlying parameters at the beginning of the study and mapped to a scatterplot graphic.
<!-- @fig-eyefitting-simplot illustrates an example of simulated data for all four parameter choices intended to reflect the trends in the original study. -->
When participants started the study, they were first asked to complete two practice plots - accompanied by instructions and a .gif demonstrating the task - in order to train them in the skills associated with executing the task.
The four 'You Draw It' task plots associated with the selected parameters followed the practice plots in a random order for each individual; these plots were interspersed with plots from a different experiment.

Participants were recruited via Prolific in March 2022; while this study does utilize a convenience sample, as this is primarily a perceptual task, previous results have found few differences between expert and non-expert participants in this context [@vanderplas2015spatial].
The study was conducted and distributed via a Shiny application and participants completed the tasks on their own computer, with a computer mouse, and in an environment of their choosing.
The data from this study were collected to validate this method of graphical testing, with the hopes of providing a new tool to assess graphical perception interactively.

## Data Analysis and Results

<!-- \svp{Explain why our method works so well here - you can actually test whether the PCA residuals are closer than the OLS residuals formally, where Mosteller et al just said "seems like". Your method also extends beyond OLS using GAMMs. Fully describe the models you fit - assumptions, equations, etc.} -->

As a part of the validation study, we collected data for each participant drawn trend line, allowing us to conduct formal analyses which compared the intuitive visually fit lines to statistical regression results - the original study lacked these formal comparisons, providing only summaries of averages, variances, and actual (least squares) values for the slope and intercept of each data set.
The feedback data, stored in a SQLite database, contained the simulated data points} - $(x_{ijk}, y_{ijk})$ -, the predicted values from the statistical regression models - $\hat y_{ijk,OLS}$, and $\hat y_{ijk,PCA}$ -, and the predicted values from the user drawn line - $y_{ijk,drawn}$ for parameter choice $i = 1,2,3,4$, $j = 1,...,N_\text{participant}$, and $x_{ijk}$ value $k = 1, ...,4 x_{max} + 1$.
@fig-eyefitting-plots displays an example of all three fitted trend lines for parameter choice F.

A unique data set was simulated independently for each participant, therefore, comparisons of vertical residuals between the user drawn line and the OLS fitted values ($e_{ijk,OLS} = y_{ijk,drawn} - \hat y_{ijk,OLS}$) and PCA fitted values ($e_{ijk,PCA} = y_{ijk,drawn} - \hat y_{ijk,PCA}$) were used to assess the accuracy of participant drawn lines.
We use mixed model methods to analyze residual trends and capture the variability due to participant differences.

```{r eyefitting-plots, warning = F, message = F}
#| fig-cap: "Visual analysis results for parameter choice set F. \\linebreak \\textbf{A.} Example of validation feedback data where three trend lines show the the OLS fitted, PCA fitted, and participant drawn values overlaid on the simulated data points. \\linebreak \\textbf{B \\& C.} Estimated trends of residuals (vertical deviation of participant drawn points from both the OLS (blue) and PCA (orange) fitted points) as fit by the (B) linear mixed model and (C) generalized additive mixed model. A random sample of 75 participants was selected to display the individual participant residuals behind the overall trend."
#| out-width: \columnwidth
#| label: fig-eyefitting-plots
#| fig-res: 300
#| fig-width: 12
#| fig-height: 6
#| fig-env: figure

(eyefitting_example + ggtitle("A. Example")) + 
  (eyefitting_lmer_plot + ggtitle("B. LMER Results")) + 
  (eyefitting_gamm_plot + ggtitle("C. GAMM Results")) +
  plot_layout(ncol =  3)
```

We first fit a linear mixed model (LMM) to the OLS and PCA residuals separately using the `lmer` function in the `lme4` package [@lme4-pkg], constraining the fit to a linear trend.
Parameter choice, $x$, and the interaction between $x$ and parameter choice were treated as fixed effects with a random participant effect accounting for variation due to participant.
The LMM equation for each fit (OLS and PCA) residuals is given by:
\begin{equation}
y_{ijk,drawn} - \hat y_{ijk,fit} = e_{ijk,fit} = \left[\gamma_0 + \alpha_i\right] + \left[\gamma_{1} x_{ijk} + \gamma_{2i} x_{ijk}\right] + p_{j} + \epsilon_{ijk}
\end{equation}
\noindent where

+ $y_{ijk,drawn}$ is the drawn y-value for the $i^{th}$ parameter choice, $j^{th}$ participant, and $k^{th}$ increment of $x$-value
+ $\hat y_{ijk,fit}$ is the fitted y-value for the $i^{th}$ parameter choice, $j^{th}$ participant, and $k^{th}$ increment of $x$-value corresponding to either the OLS or PCA fit
+ $e_{ijk,fit}$ is the residual between the drawn and fitted y-values for the $i^{th}$ parameter choice, $j^{th}$ participant, and $k^{th}$ increment of $x$-value corresponding to either the OLS or PCA fit
+ $\gamma_0$ is the overall intercept
+ $\alpha_i$ is the effect of the $i^{th}$ parameter choice (F, S, V, N) on the intercept
+ $\gamma_1$ is the overall slope for $x$
+ $\gamma_{2i}$ is the effect of the parameter choice on the slope
+ $x_{ijk}$ is the $x$-value for the $i^{th}$ parameter choice, $j^{th}$ participant, and $k^{th}$ increment
+ $p_{j} \sim N(0, \sigma^2_\text{participant})$ is the random error due to the $j^{th}$ participant's characteristics
+ $\epsilon_{ijk} \sim N(0, \sigma^2)$ is the residual error.

Eliminating the linear trend constraint, we can extend the method and analysis beyond ordinary least squares by using generalized additive mixed models (GAMM) to estimate smoothing splines and allow for a more flexible residual trend. 
The `bam` function in the `mgcv` [@mgcv_pkg] package was used to fit a GAMM separately to the OLS and PCA.
Parameter choice was treated as a fixed effect with no estimated intercept and a separate smoothing spline for $x$ was estimated for each parameter choice. 
A random participant effect accounting for variation due to participant and a random spline for each participant accounted for variation in spline for each participant.
The GAMM equation for each fit (OLS and PCA) residuals is given by:
\begin{equation}
y_{ijk, drawn} - \hat y_{ijk, fit} = e_{ijk,fit} = \alpha_i + s_{i}(x_{ijk}) + p_{j} + s_{j}(x_{ijk})
\end{equation}
\noindent where

+ $y_{ijk,drawn}$ is the drawn y-value for the $i^{th}$ parameter choice, $j^{th}$ participant, and $k^{th}$ increment of $x$-value
+ $\hat y_{ijk,fit}$ is the fitted y-value for the $i^{th}$ parameter choice, $j^{th}$ participant, and $k^{th}$ increment of $x$-value corresponding to either the OLS or PCA fit
+ $e_{ijk,fit}$ is the residual between the drawn and fitted y-values for the $i^{th}$ parameter choice, $j^{th}$ participant, and $k^{th}$ increment of $x$-value corresponding to either the OLS or PCA fit
+ $\alpha_i$ is the intercept for the parameter choice $i$
+ $s_{i}$ is the smoothing spline for the $i^{th}$ parameter choice
+ $x_{ijk}$ is the $x$-value for the $i^{th}$ parameter choice, $j^{th}$ participant, and $k^{th}$ increment
+ $p_{j} \sim N(0, \sigma^2_\text{participant})$ is the error due to participant variation
+ $s_{j}$ is the random smoothing spline for each participant.

This method allows us to quantitatively compare participant lines to the OLS and principal component regression lines, which is an improvement over the qualitative approach in @mosteller1981eye.
While the statistical models were fit to all four parameter choices, @fig-eyefitting-plots displays the estimated trends of residuals (vertical deviation of participant drawn points from both the OLS and PCA fitted points) as modeled by a LMM and GAMM respectively for parameter choice set F. 
A random sample of 75 participants was selected to display individual participant residuals behind the overall residual trend.
Examining the plots, the estimated trends of PCA residuals (orange) appear to align more parallel and closer to the $y=0$ horizontal (dashed) line than the OLS residuals (blue). 
In particular, this trend was more prominent in parameter choices with large variances.
Results from our study were consistent with those found in the original study; when shown points following a linear trend, participants tended to fit the slope of the first principal component Our study established 'You Draw It' as a method for graphical testing and reinforced the differences between intuitive visual model fitting and statistical model fitting, providing information about human perception as it relates to the use of statistical graphics.

## Extension to Nonlinear Data

The analysis method presented above extends nicely beyond the linear regressions tested in @mosteller1981eye. Here we briefly demonstrate this with an example from a study examining participants ability to make forecasts for exponentially increasing data on log and linear scales. Along with analyzing the feedback data with the GAMM method for flexibility due to nonlinear data, we used spaghetti plots to conduct a visual analysis of participant forecasts compared to the nonlinear least squares statistical model and make comparisons between two chart design features [@fig-exponential-spaghetti-plot]. The combination of the GAMM analysis and visual display demonstrates the strength of the 'You Draw It' method for testing statistical graphics.

```{r eyefitting-plots, warning = F, message = F}
#| fig-cap: "Spaghetti plot of results from a study which asked participants to forecast trends of exponentially increasing data. Participants drawn lines on the linear scale are shown in blue and the log scale are shown in orange. Variability in the statistically fitted regression lines occurred due to a unique data set being simulated for each individual; the gray band shows the range fitted values from the statistically fitted regression lines."
#| out-width: \columnwidth
#| label: fig-exponential-spaghetti-plot
#| fig-res: 300
#| fig-width: 6
#| fig-height: 4
#| fig-env: figure

spaghetti_plot <- youdrawit_model_data %>%
  ggplot(aes(x = x)) +
  geom_line(aes(y = yloess, group = plot_id, color = scale), alpha = 0.2) +
  geom_ribbon(data = youdrawit_simulated_band, aes(ymin = min_ynls, ymax = max_ynls, fill = "Fitted NLS", group = NA), color = NA, alpha = 0.35) +
  # facet_grid(`Growth Rate` ~ `Points Truncated`, scales = "free", labeller = labeller(`Growth Rate` = label_both, `Points Truncated` = label_both)) +
  theme_bw() +
  theme(aspect.ratio = 1,
        legend.position = "right"
        ) +
  scale_color_manual("", values = c("steelblue", "orange"), labels = c("Visual fit, linear scale \n (drawn, loess)", "Visual fit, log scale \n (drawn, loess)")) +
  scale_fill_manual("", values = c("black"), labels = c("Range of fitted values \n from statistically fitted regression \n lines (NLS)")) +
  scale_x_continuous(limits = c(10, 20)) +
  scale_y_continuous("y", limits = c(0, 300), breaks = seq(0,300,50)) +
  guides(color = guide_legend(override.aes = list(alpha = 1)),
         fill = guide_legend(override.aes = list(alpha = 0.3)))
spaghetti_plot
```

<!-- \svp{It's also worth remarking on the effectiveness of the spaghetti plots and GAMM plots for visual analysis of the results. Gotta keep pounding the "visual analytics is statistics" drum a bit :). } -->

# Conclusion

The data presented in this paper are part of a much broader experiment on the perception of log scales; while this paper focuses primarily on the computational implementation of the 'You Draw It' method and its adaptation to testing graphics, we are currently finishing the analysis and description of the broader experiment, which uses this 'You Draw It' method to assess user prediction of exponential trends.

By introducing an interactive method for assessing eye-fit data summaries, along with an analysis method which allows us to test competing hypotheses to determine whether user responses are similar to particular statistical models, we have provided another tool for experimentally testing statistical charts. In the future, we hope to create an R package to more easily facilitate these types of user experiments, making this technique available to other researchers who may not be willing to tinker with JavaScript directly.

As with any method for testing statistical graphics, there are a host of additional studies which would be useful to understand how users react to the 'You Draw It' method and what parameters are most important for the researcher to control. One avenue of future exploration is to investigate the effect of axis limits on user anchoring. We know that the perceptual experience is heavily affected by anchoring to e.g. axis breaks, and we would expect that a similar anchoring effect might be present based on the limits of the plot and the amount of space in $x$ and $y$ provided for the user to draw.

<!-- \svp{XXX add references to the anchoring bit XXX} -->


# Supplementary Material {-}

+ **'You Draw It' Demonstration Applet:** The shiny app used to demonstrate the 'You Draw It' method can be accessed at  [emily-robinson.shinyapps.io/you-draw-it-validation-applet](https://emily-robinson.shinyapps.io/you-draw-it-validation-applet/).
+ **'You Draw It' Script:** The 'You Draw It' JavaScript code can be accessed at  [github.com/earobinson95/presentations/blob/master/can-you-draw-it/www/you-draw-it.js](https://github.com/earobinson95/presentations/blob/master/can-you-draw-it/www/you-draw-it.js).
+ **Study Applet:** The shiny app used to conduct the study can be accessed at  [shiny.srvanderplas.com/perception-of-statistical-graphics/](https://shiny.srvanderplas.com/perception-of-statistical-graphics/).
+ **Study Applet Code:** The code used to create the RShiny Applet for data collection can be found at [github.com/earobinson95/log-perception-prolific/tree/main/perception-of-statistical-graphics](https://github.com/earobinson95/log-perception-prolific/tree/main/perception-of-statistical-graphics).
+ **Participant Data (Linear):** De-identified participant data collected in the study and used for analyses are available to be downloaded from GitHub at  [github.com/earobinson95/sdss-2022-you-draw-it-manuscript/raw/master/data/eyefitting-model-data.csv](https://github.com/earobinson95/sdss-2022-you-draw-it-manuscript/raw/master/data/eyefitting-model-data.csv). 
+ **Participant Data (Nonlinear):** De-identified participant data collected in the study and used for analyses are available to be downloaded from GitHub at  [github.com/earobinson95/sdss-2022-you-draw-it-manuscript/raw/master/data/youdrawit-model-data.csv](https://github.com/earobinson95/sdss-2022-you-draw-it-manuscript/raw/master/data/youdrawit-model-data.csv). 
+ **Data Analysis Code:** The code used to replicate the nonlinear study analysis in this paper can be found at [earobinson95.github.io/sdss-2022-you-draw-it/analysis/data-analysis.html](earobinson95.github.io/sdss-2022-you-draw-it/analysis/data-analysis.html).

# References